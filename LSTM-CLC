#Time-series application for predicting SOC in a HEV battery
#Online LSTM with Continuous Lag Control (CLC)


#%% Install Project Specific Packages
from sklearn.model_selection import TimeSeriesSplit
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
import keras as K
import keras.backend as K
import seaborn as sns
from math import sqrt
import timeit
from pandas import read_csv
#%% RMSE Definition
def measure_rmse(actual, predicted):
              return sqrt(mean_squared_error(actual, predicted))
#%% Load Data
dataset = read_csv('BATTERY DATASET', header=0, index_col=0)

values = dataset.values
values = values[0:1006]  #1006
values = values.astype('float32')
# normalize features
scaler = MinMaxScaler(feature_range=(0, 1))
data = scaler.fit_transform(values)

X = data
y = data[:,2]
#%% Load Time Series Cross Validation
tscv = TimeSeriesSplit(n_splits=1005)  #1005
#%% Create Network
pred_vec = []
lag = 0
lag_vec = []
lag_val = []
true_vec = []
rmse_vec = []
timed_conf = [0]
loss_var_vec = np.ones(np.size(lag))
pred_true = [0]
pred_true_vec = [0,0,0]
Loss = []
Val_loss = []
mem_size = []
error_variance_vec = []
RMSE = []
	# split dataset for different horizon sets, H=5: X[train_index-5], y[test_index+4]
  # H=3: X[train_index-3], y[test_index+2] and H=1:X[train_index-1], y[test_index]
for train_index, test_index in tscv.split(X):
    X_train, X_test = X[train_index-1], X[test_index]
    y_train, y_test = y[train_index], y[test_index]
 
    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))
    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))
    # End program when y_test is 1005
    if test_index == 15: #1005
        break
    # Only get the last lag items in X_train
    if np.size(X_train, axis=0)>lag+2:
        X_train = X_train[-lag:]
        y_train = y_train[-lag:]
   
    # fit model
    model = Sequential()
    model.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])))
    model.add(Dense(1))
    model.compile(loss='mae', optimizer='adam', metrics=['accuracy'])
    
    start_time = timeit.default_timer()
    history = model.fit(X_train, y_train, epochs=100, batch_size=50, validation_data=(X_test, y_test), verbose=0, shuffle=False)
    elapsed = timeit.default_timer() - start_time
    elapsed = round(elapsed,3)
    timed_conf.append(elapsed)
    print('Total time of this run was:', elapsed)
    
    Losses = history.history['loss']
    Loss.append(Losses)
    Val_losses = history.history['val_loss']
    Val_loss.append(Val_losses)
    lag_vec=np.append(lag_vec,lag)
    testPredict = model.predict(X_test)
        
    #Store forecast in list of predictions
    pred_vec = np.append(pred_vec,testPredict)
    true_vec = np.append(true_vec, y_test)
    mean_error = np.mean(np.subtract(pred_vec, true_vec))    
    std_error = np.std(np.subtract(pred_vec,true_vec))
    error_variance_vec = np.append(error_variance_vec, std_error)

    #--------------------------------------------------------------------------
    # Continuous Lag Control:
    #prediction outside 95% confidence error
    if abs(testPredict-y_test)>abs(mean_error + 3*std_error):
        lag = lag+1
    #prediction outside 67% confidence error
    if abs(testPredict-y_test)>abs(mean_error + 2*std_error):
        lag = lag+1
    # low prediction beyond 1 standard deviation
    if testPredict < y_test + 1*std_error:
        lag = lag+1
    #Correction for diminishing error
    if error_variance_vec[0]<error_variance_vec[-1] and error_variance_vec[-1]<error_variance_vec[-2]:
        lag=lag-1       
    # Control on lag size (minimum cap)       
    if lag>40:
        lag=40
    #--------------------------------------------------------------------------
    # estimate prediction error
    error = measure_rmse(true_vec, pred_vec)
    RMSE = np.append(RMSE, error)
    print(' > %.3f' % error)
    K.clear_session()
